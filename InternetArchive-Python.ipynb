{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internet Archive Data Notebook\n",
    "Author: Juniper Johnson, in partnership with Lawerence Evalyn (Nortehastern University Library)\n",
    "\n",
    "This file serves as the working file interacting and downloading materials from the Internet Archive. This Juypter notebook will utilize the [Internet Archive command tool for developers](https://archive.org/developers/quick-start-pip.html). Specifically, it will be used to download materials from the [Medical Heritage Library's medical journal collection](https://web.archive.org/web/20240703053640/http://www.medicalheritage.org/wp-content/uploads/2015/03/Serial-Titles-User-List_v8.csv). The MHL website has been archived as the progest disbanded in June 2024 after fifteen years of work. \n",
    "\n",
    "This notebook contains scripts to download files from IA based on a number of workflows: a CSV of text information (including unique identifiers) and a collection of IA texts created on the IA interface. The script downloads files based on date of publication, which can be altered based on whatever metadata field desired. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "The tasks that happened before working in the Jypter Notebook include installing pip and Internet Archive package in the command terminal of my laptop. This is detailed in the IA command tool tutorials.\n",
    "\n",
    "The next tasks was to create a working directory of folders for the year of publication for the different texts. I did this by creating MD formula in the CSV file (=\"MD\"&\" \"&[YEAR CELL]). This was copied for all of the items in the list and then made as a .bat file in the working directory I wanted to put them into. One thing of importance for decision making is that there is not a uniform format for the issue date. However, I am going to use the field \"Date of First Issue\" to simply this task as it has only one year date and I will look at the repetitions as a data cleaning tasks. All of the batch processing of folders was done using this [EXCEL tutorial](https://www.youtube.com/watch?v=AIBw3g_JHnI.)\n",
    "\n",
    "Order of operations: \n",
    "1. Import all packages needed for code (pandas, internetarchive, etc.).\n",
    "2. Read CSV into dataframe, extracting the column of unique identifiers (collumn G or 7 or unique-identifiers) into a list.\n",
    "3. Create pipeline for downloading all the medical journals in the list.\n",
    "4. Download the medical journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries and packages for tutorial.\n",
    "\n",
    "import pandas as pd        # Python package that allows one to make and manipulate dataframes.\n",
    "import os                  # Python package that allows for interacting and looking up operating system information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and set current working directory! \n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for reading in a CSV file into a dataframe and creating a list of desired CSV columns or fields.\n",
    "# Create a new dataframe (df) that holds the contents of the entire CSV file. Manually enter file name by replacing \"CSV-FILE-TILE.csv\"\n",
    "df = pd.read_csv('CSV-FILE-TITLE.csv', delimiter=',')\n",
    "\n",
    "print(df)\n",
    "print(df['column-title']) # prints certain columns in the data frame made from the CSV file above.\n",
    "\n",
    "# Code for writing a list of the column unique-identifiers from the csv file. The unique identifiers are the IA identifiers for each file in the corpus.\n",
    "unique_identifiers_list = list(df['unique-identifiers'])\n",
    "print(unique_identifiers_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for interacting with internet archive files. \n",
    "# This is taken from the IA tutorial (avove) and is an exercise for how to interact with the internet archive package.\n",
    "\n",
    "from internetarchive import get_item\n",
    "item = get_item('aesculapian1188unse') # Replace unique identifer for any text or source on IA to see metadata for file.\n",
    "for k,v in item.metadata.items():\n",
    "    print(print(k,\":\",v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for downloading individual files from IA. To edit this, simply replace the unique identifier as seen here: download('unique-identifer'). Full information about the synatax for this function can be found at:https://archive.org/developers/internetarchive/api.html#internetarchive.download.\n",
    "# To download certain formats, you can use the \"formats: str\" parameter, for example formats: txt. \n",
    "# To download files to a certain directory, you can use the parameter \"destdir: str\" to indicate where it should be. Otherwise, you can add the parameter \"no_directory\" for downloading the files to the current working directory. \n",
    "\n",
    "from internetarchive import download\n",
    "from internetarchive import get_item\n",
    "item = get_item('aesculapian1188unse')\n",
    "single_text_date = item.item_metadata['metadata']['date']\n",
    "dirpath = r'./' # get file path (you can change this)\n",
    "single_text_directory = dirpath + single_text_date\n",
    "\n",
    "# print(single_text_date)\n",
    "download('aesculapian1188unse', verbose=True, glob_pattern='*txt', destdir = single_text_directory )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for downloading plain text files from Internet Archive from a CSV file. \n",
    "# This was created to utilize the American Medical Journal collection (3000+ texts) created by the Medical Heritage Library.\n",
    "# Import all the packages needed for the code.\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check and set current working directory (if needed)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "# Using pandas to create a data frame from a CSV file.\n",
    "df = pd.read_csv('MHL-Journals.csv', delimiter=',')\n",
    "\n",
    "# print(df)\n",
    "# print(df['unique-identifiers']) # prints certain columns in the data frame made from the CSV file above.\n",
    "\n",
    "# Code for writing a list of the column unique-identifiers from the csv file. \n",
    "unique_identifiers_list = list(df['unique-identifiers'])\n",
    "dirpath = r'./MHL-Corpus-DATE/' # Set file directory path for where texts will be downloaded.\n",
    "\n",
    "# Pulling the needed functions from the python packages imported above. \n",
    "from internetarchive import download\n",
    "from internetarchive import get_item\n",
    "\n",
    "# This is the loop that downloads files from IA into folders based on the date in their metadata.\n",
    "for identifier in unique_identifiers_list: # creating a variable for this loop\n",
    "    item = get_item(identifier) \n",
    "    single_text_date = item.item_metadata['metadata']['date'] # look into item metadata for date of publication\n",
    "    single_text_directory = dirpath + single_text_date # create a variable that adds the file path and the date\n",
    "    download(identifier, verbose=True, glob_pattern='*txt', destdir = single_text_directory ) # download plain text files into the established directory from the list of unique identifiers, looping until it is all done.\n",
    "# To dowload files into a different directory than that by date, simily change the \"single_text_directory\" to a file name in the following format: (\"r'./Folder-Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to download a single file into a specified directory based on the unique identifer.\n",
    "download('unique-identifier', verbose=True, glob_pattern='*txt', destdir = r'./Folder-Title') #Replace the unique identifier and Folder location with desired values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
